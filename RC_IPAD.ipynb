{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOvZx5a4o9y1Olc+TcJ6IcE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ponakilan/vid-anomaly/blob/main/RC_IPAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh6oTYaNu5Xn",
        "outputId": "4d64063e-be21-4340-ca72-822dc30515a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! 7z x '/content/drive/MyDrive/Research Credit/IPAD_dataset.zip'\n",
        "\n",
        "! unzip -q '/content/drive/MyDrive/Research Credit/IPAD_dataset.zip' 'IPAD_dataset/R01/training/frames/*'"
      ],
      "metadata": {
        "id": "UJis6ZUt5yIA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "from transformers import ViTFeatureExtractor, ViTModel\n",
        "import numpy as np\n",
        "\n",
        "SEQ_LEN = 10\n",
        "BATCH_SIZE = 10\n",
        "TRAIN_DIR = \"/content/IPAD_dataset/R01/training/frames\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
        "model = ViTModel.from_pretrained('google/vit-base-patch16-224').to(device)  # Move model to GPU\n",
        "\n",
        "\n",
        "def get_vit_embeddings(image_batch, labels_batch):\n",
        "    image_batch = image_batch.numpy().astype(np.float32) / 255.0\n",
        "    image_batch = [img for img in image_batch]\n",
        "\n",
        "    inputs = feature_extractor(images=image_batch, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "    return embeddings, labels_batch\n",
        "\n",
        "\n",
        "def replace_labels_with_images(x, y):\n",
        "    return x, x\n",
        "\n",
        "\n",
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=TRAIN_DIR,\n",
        "    batch_size=SEQ_LEN,\n",
        "    image_size=(224, 224),\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "dataset = dataset.map(replace_labels_with_images)\n",
        "\n",
        "dataset = dataset.map(lambda x, y: tf.py_function(\n",
        "    func=get_vit_embeddings, inp=[x, y], Tout=(tf.float32, tf.float32))\n",
        ")\n",
        "\n",
        "dataset = dataset.batch(BATCH_SIZE)  # (B, N, E)\n",
        "\n",
        "print(f\"Number of batches in the dataset: {len(dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER0yHG8UvaW9",
        "outputId": "258da5dc-d8e6-4068-d7b9-6675e02b27c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7808 files belonging to 34 classes.\n",
            "Number of batches in the dataset: 79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "embed, image = next(iter(dataset))\n",
        "embed.shape, image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15rGCmjS-2Qp",
        "outputId": "0cc4c319-5101-40ef-d2fa-030aeb5b41a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([10, 10, 768]), TensorShape([10, 10, 224, 224, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}